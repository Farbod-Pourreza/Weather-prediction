# ðŸ“Š Comparative Analysis of RNN Architectures for Time Series Prediction

This project conducts a detailed comparative study of three recurrent neural network architecturesâ€”**Long Short-Term Memory (LSTM)**, **Gated Recurrent Unit (GRU)**, and **vanilla Recurrent Neural Network (RNN)**â€”applied to time series prediction tasks.

---

## ðŸ§© Motivation

Recurrent neural networks are widely used for sequential data modeling. This project aims to evaluate and compare the predictive performance of LSTM, GRU, and RNN models on a real-world dataset, helping to understand their strengths and weaknesses in practice.

---

## ðŸ§ª Project Highlights

- Developed and trained LSTM, GRU, and RNN models for forecasting time-dependent data.
- Implemented feature normalization using **StandardScaler** to improve model convergence and accuracy.
- Evaluated models with comprehensive metrics:
  - Mean Absolute Error (MAE)
  - Mean Squared Error (MSE)
  - Root Mean Squared Error (RMSE)
  - R-squared (RÂ²)
- Analyzed model results to identify best-performing architectures for the task.

---

## ðŸ”§ Technologies Used

- **Python**
- **TensorFlow / Keras** â€“ Model building and training
- **scikit-learn** â€“ Data preprocessing and evaluation metrics
- **NumPy / Pandas** â€“ Data manipulation and analysis
- **Matplotlib / Seaborn** â€“ Visualization of results

---
